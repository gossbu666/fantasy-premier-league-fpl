"""
Feature Engineering for FPL - FINAL VERSION WITH DEBUGGING
"""

import pandas as pd
import numpy as np
from utils import logger

def create_rolling_features(data, horizons=[1, 3, 5, 10]):
    features = pd.DataFrame(index=data.index)
    data = data.sort_values(['player_id', 'round']).copy()
    
    metrics = ['total_points', 'minutes', 'goals_scored', 'assists', 
               'clean_sheets', 'goals_conceded', 'bonus', 'bps',
               'influence', 'creativity', 'threat', 'ict_index']
    
    if 'saves' in data.columns:
        metrics.append('saves')
    if 'value' in data.columns:
        metrics.append('value')
    if 'selected' in data.columns:
        metrics.append('selected')
    if 'transfers_in' in data.columns:
        metrics.extend(['transfers_in', 'transfers_out'])
    
    for metric in metrics:
        if metric not in data.columns:
            continue
        for horizon in horizons:
            col_name = f'{metric}_avg_{horizon}gw'
            features[col_name] = data.groupby('player_id')[metric].transform(
                lambda x: x.shift(1).rolling(window=horizon, min_periods=1).mean()
            )
    
    logger.info(f"   ✓ Created {len(features.columns)} rolling features")
    return features

def create_features(data, position):
    logger.info(f"Creating features for {position}...")
    data = data.sort_values(['player_id', 'round']).reset_index(drop=True)
    
    features = pd.DataFrame(index=data.index)
    features['player_id'] = data['player_id'].values
    features['round'] = data['round'].values
    
    if 'player_name' in data.columns:
        features['player_name'] = data['player_name'].values
    
    features['target'] = data['total_points'].values
    
    rolling = create_rolling_features(data)
    features = pd.concat([features, rolling], axis=1)
    
    if 'fdr_attack' in data.columns:
        features['fdr_attack'] = data['fdr_attack'].values
        features['fdr_defense'] = data['fdr_defense'].values
        features['is_home'] = data['is_home'].astype(int).values
        logger.info("   ✓ Added FDR features")
    
    initial_len = len(features)
    features = features[features['round'] > 1].copy()
    logger.info(f"   ✓ Removed GW1: {initial_len - len(features)} rows")
    
    features = features.dropna(subset=['target'])
    features = features.fillna(0)
    
    logger.info(f"✓ Created features DataFrame:")
    logger.info(f"  - Total columns: {len(features.columns)}")
    logger.info(f"  - Total rows: {len(features)}")
    logger.info(f"  - Gameweeks: {features['round'].min():.0f} to {features['round'].max():.0f}")
    logger.info(f"  - Has 'round': {'round' in features.columns}")
    logger.info(f"  - Has 'player_id': {'player_id' in features.columns}")
    
    return features

def prepare_features(features_df, position):
    logger.info(f"Preparing features for training...")
    
    metadata_cols = ['target', 'player_id', 'player_name', 'round']
    X = features_df.drop(metadata_cols, axis=1, errors='ignore')
    y = features_df['target']
    rounds = features_df['round'].values
    player_ids = features_df['player_id'].values
    
    logger.info(f"✓ Extracted data:")
    logger.info(f"  - X shape: {X.shape}")
    logger.info(f"  - y shape: {y.shape}")
    logger.info(f"  - rounds shape: {rounds.shape}")
    logger.info(f"  - player_ids shape: {player_ids.shape}")
    logger.info(f"  - Unique players: {len(np.unique(player_ids))}")
    
    return X, y, rounds, player_ids

def calculate_sample_weights(y):
    def categorize(points):
        if points == 0: return 'zero'
        elif points <= 2: return 'blank'
        elif points <= 4: return 'ticker'
        else: return 'hauler'
    
    categories = y.apply(categorize)
    weights = categories.map({'zero': 0.5, 'blank': 1.0, 'ticker': 1.5, 'hauler': 3.0})
    return weights

def process_position(position):
    from sklearn.preprocessing import MinMaxScaler
    import joblib
    from pathlib import Path
    
    logger.info("="*60)
    logger.info(f"Processing {position} (WITH DEBUGGING)")
    logger.info("="*60)
    
    data_file = f'data/processed/{position}_data.csv'
    data = pd.read_csv(data_file)
    logger.info(f"✓ Loaded {len(data)} records from {data_file}")
    logger.info(f"  Columns: {list(data.columns)[:10]}...")
    
    features = create_features(data, position)
    X, y, rounds, player_ids = prepare_features(features, position)
    
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)
    logger.info("✓ Normalized features")
    
    sample_weights = calculate_sample_weights(y)
    logger.info(f"✓ Sample weights calculated")
    
    # BUILD RESULT DATAFRAME
    logger.info("Building result DataFrame...")
    result = pd.DataFrame()
    
    # Add scaled features
    for col in X_scaled_df.columns:
        result[col] = X_scaled_df[col].values
    
    # Add metadata
    result['target'] = y.values
    result['sample_weight'] = sample_weights.values
    result['round'] = rounds
    result['player_id'] = player_ids
    
    # Verify
    logger.info(f"✓ Result DataFrame built:")
    logger.info(f"  - Shape: {result.shape}")
    logger.info(f"  - Last 5 columns: {list(result.columns)[-5:]}")
    
    assert 'target' in result.columns, "ERROR: target missing!"
    assert 'round' in result.columns, "ERROR: round missing!"
    assert 'player_id' in result.columns, "ERROR: player_id missing!"
    assert len(result) == len(X), "ERROR: row count mismatch!"
    
    logger.info(f"✓ All assertions passed!")
    
    output_file = f'data/processed/{position}_features.csv'
    result.to_csv(output_file, index=False)
    logger.info(f"✓ Saved to {output_file}")
    
    # Verify save
    test_load = pd.read_csv(output_file)
    logger.info(f"✓ Verified saved file:")
    logger.info(f"  - Columns: {len(test_load.columns)}")
    logger.info(f"  - Has 'round': {'round' in test_load.columns}")
    logger.info(f"  - Has 'player_id': {'player_id' in test_load.columns}")
    
    Path('models').mkdir(exist_ok=True)
    joblib.dump(scaler, f'models/{position}_preprocessor.pkl')
    logger.info(f"✓ Saved preprocessor\n")

def main():
    logger.info("="*80)
    logger.info("FEATURE ENGINEERING - NO LEAKAGE + METADATA (WITH DEBUG)")
    logger.info("="*80)
    
    positions = ['GK', 'DEF', 'MID', 'FWD']
    
    for position in positions:
        try:
            process_position(position)
        except Exception as e:
            logger.error(f"✗ Error: {position}: {e}")
            import traceback
            traceback.print_exc()
    
    logger.info("="*80)
    logger.info("✓ PHASE 2 COMPLETE!")
    logger.info("="*80)

if __name__ == '__main__':
    main()
